{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdcJZLa1g4FgK5jfCjCqju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hertie-School-Machine-Learning-F2022/Class_lab_05/blob/main/Class_Lab_05_GRAD_C24_fall_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression\n",
        "\n",
        "## Author: Paulina Garcia Corral\n",
        "\n",
        "Regression is a method of modelling a target value (y) based on independent values. In plain english, predicting the value of some variable y, based on the values of other variables we think influence it. Regression techniques differ on number of independent variables (linear regression, multilinear regression) and on the type of relationship between target and predictors (polynomials).\n",
        "\n",
        "##¬†Simple linear regression\n",
        "\n",
        "The relationship between one independent variable (x) and one dependent variable (y). The modelling produces a straight line of best fit, which models the points using the linear equation (y = mx + b).\n",
        "\n",
        "In statistics, the linear equation is usually expressed as: \n",
        "\n",
        "##¬†y' = Œ≤0 + Œ≤1*X1 + e\n",
        "\n",
        "With a bigger number of independent variables, or a model that has multiple _features_ (x1, x2, etc), each with a different weight (b_1, b_2, etc) the equation expands like this:\n",
        "\n",
        "##¬†y' = Œ≤0 + Œ≤1*X1 + Œ≤2*X2 + Œ≤3*X3 + Œ≤i*Xi + ùúÄ"
      ],
      "metadata": {
        "id": "wpSr0JxR-HL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the example below: \n",
        "\n",
        "We have recorded the temperature in Celsius each day and the number of cricket chirps. \n",
        "\n",
        "We want to find out if the temperature influences the number of chirps. \n",
        "\n",
        "We set X as our independent variable (Temperature in ¬∫C) \n",
        "\n",
        "and y as our dependent variable (Number of chirps)"
      ],
      "metadata": {
        "id": "r7cZgP-kCqF-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "_k_luqNO-Ejx",
        "outputId": "8efe5518-71ea-4ee4-bb1f-0856cc64e056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y' = -4.11 + 0.65 *X1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [10, 15, 20, 25, 30, 35, 40]\n",
        "y = [3, 5, 8, 13, 16, 18, 22]\n",
        "\n",
        "coef = np.polyfit(x,y,1)\n",
        "poly1d_fn = np.poly1d(coef) \n",
        "\n",
        "plt.plot(x,y, 'yo', x, poly1d_fn(x), '--k');\n",
        "\n",
        "plt.xlim(10, 40);\n",
        "plt.ylim(3, 25);\n",
        "\n",
        "print(\"Y' =\", \"%.2f\" % coef[1], '+', \"%.2f\" % coef[0], '*X1')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of linear regression in Machine Learning is to use the line of best fit, to estimate the values of unseen data samples.\n",
        "\n",
        "For example, using the estimator, when the temprature is equal to 23¬∫C (x = 23), we estimate to hear aprox 11 chirps (y' = 10.84)."
      ],
      "metadata": {
        "id": "iOZN2E3xB7Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Equation')\n",
        "print(\"Y' =\", \"%.2f\" % coef[1], '+', \"%.2f\" % coef[0], '*X1')\n",
        "print(\"Y' =\", \"%.2f\" % coef[1], '+', \"%.2f\" % coef[0], '*Temp')\n",
        "print(\"\")\n",
        "print('Substitute')\n",
        "print(\"y' =\", \"%.2f\" % coef[1], '+', \"%.2f\" % coef[0], '*23¬∫C')\n",
        "print(\"y' =\", \"%.2f\" % (coef[1] + (coef[0]*23)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x519UiQzFNWE",
        "outputId": "df23b0e5-975a-4206-d0c4-e168ad3f4678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equation\n",
            "Y' = -4.11 + 0.65 *X1\n",
            "Y' = -4.11 + 0.65 *Temp\n",
            "\n",
            "Substitute\n",
            "y' = -4.11 + 0.65 *23¬∫C\n",
            "y' = 10.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression is a minimization problem\n",
        "\n",
        "The objetive is to minimize the error between the predicted value and the actual value.\n",
        "\n",
        "What do we mean by this? \n",
        "\n",
        "Let's look at our real data:\n",
        "\n",
        "x = [10, 15, 20, 25, 30, 35, 40]\n",
        "\n",
        "y = [3, 5, 8, 13, 16, 18, 22]\n",
        "\n",
        "\n",
        "Take the actual value of x = 15, we _know_ the real value of y =5 when x = 15. \n",
        "\n",
        "But using the equation above, we estimate that the value of y' = 5.64"
      ],
      "metadata": {
        "id": "gXSjY3SuGz-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Equation')\n",
        "print(\"y' =\", \"%.2f\" % coef[1], '+', \"%.2f\" % coef[0], '*x_1')\n",
        "print(\"\")\n",
        "print('Substitute')\n",
        "print(\"y' =\", \"%.2f\" % coef[1], '+', \"%.2f\" % coef[0], '*15')\n",
        "print(\"y' =\", \"%.2f\" % (coef[1] + (coef[0]*15)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug5TlgmBHrKC",
        "outputId": "ae9de924-653c-41a7-889a-bfaa52ee6bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equation\n",
            "y' = -4.11 + 0.65 *x_1\n",
            "\n",
            "Substitute\n",
            "y' = -4.11 + 0.65 *15\n",
            "y' = 5.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objetive of linear regression is to minimize the difference between the real value and the predict value as much as we can, to generate better predictions. "
      ],
      "metadata": {
        "id": "tutf0w6yH1xz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a Linear Regression model, training or fitting a model simply means determining or finding good values for all the weights (the b's for each x) and the bias (B0 or coefficient) from labeled examples. In supervised learning, a machine learning algorithm builds a model by examining many examples and attempting to find a model that minimizes loss, or the difference between actual and predicted value (y - y').\n",
        "\n",
        "In linear regression models one loss function used to calculate the weights is called squared loss (also known as L2 loss). The squared loss for a single example is as follows: \n",
        "\n",
        "\n",
        " Mean Squared Error = (Œ£(y - prediction(x))^2)/N"
      ],
      "metadata": {
        "id": "HvvYPWdUHHnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#¬†This looks familiar, many results metrics take this form!\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mse_results = mean_squared_error(y_test, y_pred) #y_test is the actual value of y that is saved in our test set\n",
        "                                                 #y_pred is the predicted value of y according to our model"
      ],
      "metadata": {
        "id": "LdDlZJWqGuqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's keep using the temprature and cricket chirping example to further demostrate. "
      ],
      "metadata": {
        "id": "CM4GnWQJK0j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imagine that we have a bigger dataset, and we have divided that set into testing\n",
        "# and training, like below. \n",
        "# (For sklearn, the dimensions of the arrey have to be in 2D, set as -1,1)\n",
        "\n",
        "X_train = np.reshape([10, 15, 20, 25, 30, 35, 40], (-1, 1))\n",
        "y_train = np.reshape([3, 5, 8, 13, 16, 18, 22], (-1, 1))\n",
        "\n",
        "X_test = np.reshape([13, 14, 15, 16], (-1,1))\n",
        "y_test = np.reshape([3, 5, 5, 7], (-1, 1))"
      ],
      "metadata": {
        "id": "8oN1FE2icZYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Linear Regression from linear_model\n",
        "\n",
        "\n",
        "# Set Linear Regression as our model (lm)\n",
        "\n",
        "\n",
        "\n",
        "# Fit with the training set, which in this case means calculating the line of best fit\n",
        "# and obtaining the bias and weights (B0 and Bi or intercept and coefficients or alpha and beta i)\n",
        "\n",
        "\n",
        "\n",
        "print('bias or intercept',#)\n",
        "print('weight or coef', #)"
      ],
      "metadata": {
        "id": "sYPdLkg2cZ26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##¬†Recall our test data\n",
        "\n",
        "**x = 13, 14, 15, 16**\n",
        "\n",
        "**y = 3, 5, 5, 7**\n",
        "\n",
        "What happens now is that the model will take the X values, and predict y using the equation that was fitted above using the bias and the weight.\n",
        "\n",
        "_y' = -4.107 + 0.65*Temp_\n"
      ],
      "metadata": {
        "id": "9VDuYnIii9CV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Of course, that's when our sklearn functions come in\n",
        "# We can now predict on unseen data!\n",
        "\n",
        "y_pred = "
      ],
      "metadata": {
        "id": "kqQMIm34caVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can compare the real values of y (y_test) and the predicted values of y (y_pred)\n",
        "\n",
        "print('y_test:')\n",
        "print(y_test)\n",
        "print(\"\")\n",
        "print('y_pred:')\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "id": "NE87rFNEcarQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean squared error \n",
        "\n"
      ],
      "metadata": {
        "id": "hpucsPo9eQ4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and the R^2 as an additional metric \n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n"
      ],
      "metadata": {
        "id": "C3w703CseTsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both MSE and R2 quantify how well a regression model fits a dataset. The RMSE tells us how well a regression model can predict the value of the response variable in absolute terms while R2 tells us how well a model can predict the value of the response variable in percentage terms"
      ],
      "metadata": {
        "id": "A31bl62rezH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How can we interpret the results? \n",
        "\n",
        "**bias and weights**\n",
        "\n",
        "**bias**: mean value of y' when X are equal to zero. In this case, when X = 0, we would hear -4.1 chirps. It makes no sense, so there is no interpretation, as it is impossible to hear negative chirps. However, we need this intercept for the model.\n",
        "\n",
        "**weights**: in average how much y increases by each unit increase of x. 0.65 extra chirps per ¬∫C. \n",
        "\n",
        "MSE and R^2\n",
        "\n",
        "**MSE**: measures how close a regression line is to a set of data points\n",
        "\n",
        "**R^2**: tells us how much variance is explained by the model"
      ],
      "metadata": {
        "id": "mdRMMiIme3rj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now let's apply a full pipeline!"
      ],
      "metadata": {
        "id": "x6ZpV5nYg2mh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this excercise I'm adapting Will Lowe's linear regression Percept 7 and 8 lab in R for Python."
      ],
      "metadata": {
        "id": "9DtLpgrVlp3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use The Electric Company on children's reading ability, an experiment by Cooney (1976). "
      ],
      "metadata": {
        "id": "XXnoGzFilzGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset called electric-company.csv\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['electric-company.csv']))\n",
        "\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "metadata": {
        "id": "eO9IKOSTfNl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This experiment tried to measure if watching an educational tv program helped students improve their reading. Every observation is a class of students, which was either treated, if the program was shown to them, or control if the program was not shown as part of their studies.\n",
        "\n",
        "The outcome of interest, our ‚Äòdependent variable‚Äô, is the class‚Äôs average score on a reading test at the end of the year. We‚Äôve called that post.score."
      ],
      "metadata": {
        "id": "gZG4an1nnHAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the data look like \n",
        "\n",
        "df.head()\n",
        "\n",
        "# City: Fresno (F) or Youngstown (Y)\n",
        "# Grade: School grade 1-4\n",
        "# Supp: Wheter the program replaced (R) or supplemented (S) a reading activity\n",
        "# Treatment: T if the children recieved treatment or C otherwise\n",
        "# Pre.score: Reading score before treatment\n",
        "# Post.score: Reading score after treatment"
      ],
      "metadata": {
        "id": "Yrj4a20VmVBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "VrhikeudnEGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will not focus on the experiment for now, and only look at the children's scores in total (both T and C)."
      ],
      "metadata": {
        "id": "OUUX-6k3L0AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's do a simple linear regression.\n",
        "# We will attempt to predict readings score based on school grade\n",
        "\n",
        "# \n",
        "\n",
        "\n",
        "print(\"coef:\", #)\n",
        "print(\"intercept:\", #)\n",
        "print(\"R2:\", #)\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "p85_FQfyq17m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, we are only considering that given a child's school grade, we can predict it's learning score.\n",
        "\n",
        "We see that according to the model, every extra year of schooling, increases the score by 12.32 points."
      ],
      "metadata": {
        "id": "BWS7PmGCrUuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Two variables to observe if this increases the variance explained\n",
        "\n",
        "x =  # Add the previous score\n",
        "y = df[['post.score']]\n",
        "\n",
        "y_pred = lm.fit(x,y).predict(x)\n",
        "\n",
        "print(\"coef:\", #)\n",
        "print(\"intercept:\", #)\n",
        "print(\"R2:\", #)"
      ],
      "metadata": {
        "id": "zmvlODGvNEtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n"
      ],
      "metadata": {
        "id": "p85BMQ-532iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There seems to be space for improvement if we add a StandardScaler \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "stdsc = StandardScaler()\n",
        "lm = LinearRegression()\n",
        "\n",
        "# Create a pipeline\n",
        "\n",
        "\n",
        "print(\"coef:\", #)\n",
        "print(\"intercept:\", #)\n",
        "print(\"R2:\", #)"
      ],
      "metadata": {
        "id": "ZkrmF67F6i8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if we add an interaction term? There are advantages to understanding the effects of variables that together have more predictive power."
      ],
      "metadata": {
        "id": "RI_7S_ym6tt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can add more variables to observe if this increases the variance explained\n",
        "xy = \n",
        "\n",
        "x = # Add the previous score\n",
        "y = df[['post.score']]\n",
        "\n",
        "# Plot\n"
      ],
      "metadata": {
        "id": "-dAzdOBn6881"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit linear regression with 3 variables (previous two + interaction term)\n",
        "\n",
        "# pipe\n",
        "\n",
        "\n",
        "\n",
        "print(\"coef:\", #)\n",
        "print(\"intercept:\", #)\n",
        "print(\"R2:\", #)"
      ],
      "metadata": {
        "id": "yqua0hLc7hDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear from the data that the classess are grouping together, and that they should probably be treated as categorical instead of numerical."
      ],
      "metadata": {
        "id": "6KLL3qUENu8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to use one hot encoder\n",
        "\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Instanciate ohe and drop first dummy to make it easier to interpret\n",
        "\n",
        "\n",
        "# Preprocess \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a pipeline\n",
        "\n",
        "\n",
        "# Fit\n",
        "\n",
        "\n",
        "# Get the values  \n",
        "print('Feat:', #)\n",
        "print('Coef:', #)\n",
        "print('Inter:', #)\n",
        "print(\"R2:\", #)"
      ],
      "metadata": {
        "id": "71hhe6zsrveT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}